#!/usr/bin/env python3
"""
Plot accuracy vs n_tracked_updates to visualize the trend
"""

import os
import glob
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import argparse
from config_utils import get_n_tracked_keys_for_test, create_directory_pattern
import scipy.stats as stats

def compute_ci95_width_by_bootstrap(acc, n=5000):
    """Compute the width of the 95% confidence interval by bootstrapping."""
    if len(acc) <= 1:
        return np.nan, 0

    acc = np.array(acc)
    # è¿›è¡Œbootstrapé‡‡æ ·
    arr = [np.mean(np.random.choice(acc, len(acc), True)) for _ in range(n)]
    arr.sort()
    width = np.percentile(arr, 97.5) - np.percentile(arr, 2.5)
    return width, len(acc)

def extract_n_tracked_updates(dir_name):
    """Extract n_tracked_updates value from directory name"""
    if "_ntrkupd-" in dir_name:
        try:
            return int(dir_name.split("_ntrkupd-")[1].split("_")[0])
        except:
            return None
    return None

def extract_len_item(dir_name):
    """Extract len_item value from directory name"""
    if "_lenitm-" in dir_name:
        try:
            return int(dir_name.split("_lenitm-")[1].split("_")[0])
        except:
            return None
    return None

def extract_accuracy_from_csv(csv_file):
    """Extract accuracy from CSV file and calculate mean and 95% CI using bootstrap method"""
    try:
        df = pd.read_csv(csv_file)
        if 'accuracy' in df.columns and not df.empty:
            # ç»Ÿè®¡æ€»æ•°æ®å’Œæœ‰æ•ˆæ•°æ®
            total_rows = len(df)
            accuracies_with_nan = df['accuracy']
            accuracies = accuracies_with_nan.dropna().values
            valid_rows = len(accuracies)
            nan_rows = total_rows - valid_rows
            
            if len(accuracies) == 0:
                print(f"Warning: No valid accuracy data in {csv_file}")
                return None
            
            # å¦‚æœæœ‰ç¼ºå¤±æ•°æ®ï¼ŒæŠ¥å‘Šä¸€ä¸‹
            if nan_rows > 0:
                print(f"Info: {csv_file} - {nan_rows}/{total_rows} rows with missing accuracy data were excluded")
            
            mean_acc = np.mean(accuracies)
            ci95_width, n = compute_ci95_width_by_bootstrap(accuracies)
            return {
                'mean': mean_acc,
                'ci95': ci95_width / 2,  # è½¬æ¢ä¸ºå•è¾¹è¯¯å·®
                'n': n,  # æœ‰æ•ˆæ•°æ®æ•°é‡
                'total_rows': total_rows,  # æ€»è¡Œæ•°
                'valid_rows': valid_rows,  # æœ‰æ•ˆè¡Œæ•°
                'excluded_rows': nan_rows,  # è¢«æ’é™¤çš„è¡Œæ•°
                'raw_data': df  # æ·»åŠ åŸå§‹æ•°æ®
            }
    except Exception as e:
        print(f"Error reading {csv_file}: {e}")
    return None

def collect_data(base_dir):
    """Collect n_tracked_updates and accuracy data from all test directories"""
    data = []
    raw_data_list = []  # ç”¨äºå­˜å‚¨æ‰€æœ‰åŸå§‹æ•°æ®
    
    # Try to determine test name from path for config lookup
    test_name = None
    path_parts = base_dir.replace('\\', '/').split('/')
    for part in path_parts:
        if part.startswith('test_'):
            test_name = part
            break
    
    # Try to get n_tracked_keys from config
    n_tracked_keys = None
    if test_name:
        n_tracked_keys = get_n_tracked_keys_for_test(test_name)
        if n_tracked_keys:
            print(f"ğŸ“‹ Found n_tracked_keys={n_tracked_keys} from config for test '{test_name}'")
    
    # If we couldn't get it from config, try to infer from existing directories
    if n_tracked_keys is None:
        print("âš ï¸  Could not get n_tracked_keys from config, scanning for existing patterns...")
        # Look for any directory with ntrk pattern
        all_dirs = glob.glob(os.path.join(base_dir, "*ntrk-*_ntrkupd*"))
        if all_dirs:
            # Extract n_tracked_keys from the first directory found
            for dir_path in all_dirs:
                dir_name = os.path.basename(dir_path)
                if "_ntrk-" in dir_name and "_ntrkupd-" in dir_name:
                    try:
                        n_tracked_keys = int(dir_name.split("_ntrk-")[1].split("_")[0])
                        print(f"ğŸ“‹ Inferred n_tracked_keys={n_tracked_keys} from existing directory pattern")
                        break
                    except:
                        continue
    
    # Create pattern based on n_tracked_keys
    if n_tracked_keys is not None:
        pattern = os.path.join(base_dir, create_directory_pattern(n_tracked_keys))
        print(f"ğŸ” Using pattern: {create_directory_pattern(n_tracked_keys)}")
    else:
        # Fallback to old hardcoded pattern (for backward compatibility)
        pattern = os.path.join(base_dir, "*ntrk-46_ntrkupd*")
        print(f"âš ï¸  Falling back to legacy pattern: *ntrk-46_ntrkupd*")
    
    # Find all test directories
    test_dirs = sorted(glob.glob(pattern))
    
    print(f"Found {len(test_dirs)} test directories")
    
    for test_dir in test_dirs:
        dir_name = os.path.basename(test_dir)
        n_updates = extract_n_tracked_updates(dir_name)
        
        if n_updates is None:
            continue
            
        # Find the CSV file
        csv_pattern = os.path.join(test_dir, "*_trial.csv")
        csv_files = glob.glob(csv_pattern)
        
        if not csv_files:
            print(f"Warning: No CSV file found in {dir_name}")
            continue
            
        csv_file = csv_files[0]  # Take the first one
        accuracy = extract_accuracy_from_csv(csv_file)
        
        if accuracy is not None:
            data.append({
                'n_tracked_updates': n_updates,
                'accuracy_mean': accuracy['mean'],
                'accuracy_ci95': accuracy['ci95'],
                'n': accuracy['n'],
                'directory': dir_name
            })
            
            # æ·»åŠ åŸå§‹æ•°æ®åˆ°åˆ—è¡¨
            if 'raw_data' in accuracy:
                raw_df = accuracy['raw_data']
                raw_df['n_tracked_updates'] = n_updates
                raw_df['directory'] = dir_name
                raw_data_list.append(raw_df)
            
            print(f"âœ… n_tracked_updates={n_updates:3d}, accuracy={accuracy['mean']:.3f} Â± {accuracy['ci95']:.3f}")
        else:
            print(f"âŒ Failed to extract accuracy from {dir_name}")
    
    # ä¿å­˜åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶
    if raw_data_list:
        raw_data_df = pd.concat(raw_data_list, ignore_index=True)
        # è·å–å½“å‰å·¥ä½œç›®å½•
        current_dir = os.getcwd()
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        # ä»base_dirä¸­æå–æ¨¡å‹åç§°
        model_name = os.path.basename(base_dir)
        # æ„å»ºæ–‡ä»¶å
        raw_data_file = os.path.join(current_dir, f'raw_accuracy_data_{test_name}_{model_name}_{timestamp}.csv')
        raw_data_df.to_csv(raw_data_file, index=False)
        print(f"\nğŸ“„ Raw data saved as: {raw_data_file}")
    
    return data

def create_plot(data, output_file="accuracy_vs_n_tracked_updates.png", model_name=None, test_name=None, random_update=None):
    """Create a plot showing accuracy vs n_tracked_updates"""
    if not data:
        print("No data to plot!")
        return
        
    # Convert to DataFrame for easier handling
    df = pd.DataFrame(data)
    df = df.sort_values('n_tracked_updates')
    
    # Create the plot
    plt.figure(figsize=(12, 8))
    
    # Plot with error bars
    plt.errorbar(
        df['n_tracked_updates'],
        df['accuracy_mean'],
        yerr=df['accuracy_ci95'],
        fmt='o-',
        capsize=5,
        markersize=8,
        label='Mean with 95% CI'
    )
    
    # Add some statistics
    max_acc = df['accuracy_mean'].max()
    min_acc = df['accuracy_mean'].min()
    mean_acc = df['accuracy_mean'].mean()
    
    # Add text box with statistics
    stats_text = f'Max Accuracy: {max_acc:.3f}\nMin Accuracy: {min_acc:.3f}\nMean Accuracy: {mean_acc:.3f}\nData Points: {len(df)}'
    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8),
             verticalalignment='top', fontsize=10)
    
    # Use log scale for better visualization of the wide range
    plt.xscale('log')
    
    # Set custom x-axis ticks to show each data point exactly
    plt.xticks(df['n_tracked_updates'], labels=df['n_tracked_updates'].astype(str), rotation=45, ha='right')
    plt.xlabel('Number of Tracked Updates (log scale)', fontsize=14)
    plt.ylabel('Accuracy', fontsize=14)
    
    # Add title with model and test information
    title = "Accuracy vs Number of Tracked Updates"
    if model_name:
        title += f"\nModel: {model_name}"
    if test_name:
        title += f"\nTest: {test_name}"
    if random_update is not None:
        title += f"\nRandom Updates: {'On' if random_update else 'Off'}"
    plt.title(title, fontsize=14)
    
    # Add grid
    plt.grid(True, alpha=0.3)
    
    # Save the plot
    plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"\nğŸ“Š Plot saved as: {output_file}")
    
    # æ·»åŠ æ¨¡å‹åç§°å’Œci95è®¡ç®—æ–¹æ³•åˆ°DataFrame
    df['model_name'] = model_name if model_name else 'Unknown'
    df['ci95_method'] = 'Bootstrap (n=5000)'
    
    return df

def extract_model_from_path(path):
    """Extract model name from the path"""
    # Split the path and look for common model name patterns
    path_parts = path.replace('\\', '/').split('/')
    
    # Look for directory that looks like a model name
    for part in reversed(path_parts):
        if part and not part.startswith('eval_pi') and not part.startswith('test_'):
            # Common model name patterns
            if any(term in part.lower() for term in ['gpt', 'gemini', 'claude', 'llama', 'mistral', 'qwen']):
                return part
    
    return None

def extract_test_params_from_path(path):
    """Extract test parameters from the path"""
    path_parts = path.replace('\\', '/').split('/')
    
    test_name = None
    random_update = None
    
    for part in path_parts:
        if part.startswith('test_'):
            test_name = part
            # Check for random update indicators in test name
            if 'randomoff' in part:
                random_update = 0
            elif 'randomon' in part:
                random_update = 1
    
    return test_name, random_update

def collect_data_len_item_mode(base_dir):
    """Collect len_item and accuracy data for test_itemlen tests"""
    data = []
    raw_data_list = []
    
    # Try to determine test name from path for config lookup
    test_name = None
    path_parts = base_dir.replace('\\', '/').split('/')
    for part in path_parts:
        if part.startswith('test_'):
            test_name = part
            break
    
    # Find all test directories with len_item pattern
    pattern = os.path.join(base_dir, "*lenitm-*")
    test_dirs = sorted(glob.glob(pattern))
    
    print(f"Found {len(test_dirs)} test directories for len_item analysis")
    
    for test_dir in test_dirs:
        dir_name = os.path.basename(test_dir)
        len_item = extract_len_item(dir_name)
        n_updates = extract_n_tracked_updates(dir_name)
        
        if len_item is None or n_updates is None:
            continue
            
        # Find the CSV file
        csv_pattern = os.path.join(test_dir, "*_trial.csv")
        csv_files = glob.glob(csv_pattern)
        
        if not csv_files:
            print(f"Warning: No CSV file found in {dir_name}")
            continue
            
        csv_file = csv_files[0]
        accuracy = extract_accuracy_from_csv(csv_file)
        
        if accuracy is not None:
            data.append({
                'len_item': len_item,
                'n_tracked_updates': n_updates,
                'accuracy_mean': accuracy['mean'],
                'accuracy_ci95': accuracy['ci95'],
                'n': accuracy['n'],
                'directory': dir_name
            })
            
            # æ·»åŠ åŸå§‹æ•°æ®åˆ°åˆ—è¡¨
            if 'raw_data' in accuracy:
                raw_df = accuracy['raw_data']
                raw_df['len_item'] = len_item
                raw_df['n_tracked_updates'] = n_updates
                raw_df['directory'] = dir_name
                raw_data_list.append(raw_df)
            
            print(f"âœ… len_item={len_item:2d}, n_updates={n_updates:2d}, accuracy={accuracy['mean']:.3f} Â± {accuracy['ci95']:.3f}")
        else:
            print(f"âŒ Failed to extract accuracy from {dir_name}")
    
    # ä¿å­˜åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶
    if raw_data_list:
        raw_data_df = pd.concat(raw_data_list, ignore_index=True)
        current_dir = os.getcwd()
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        model_name = os.path.basename(base_dir)
        raw_data_file = os.path.join(current_dir, f'raw_accuracy_data_{test_name}_{model_name}_{timestamp}.csv')
        raw_data_df.to_csv(raw_data_file, index=False)
        print(f"\nğŸ“„ Raw data saved as: {raw_data_file}")
    
    return data

def create_len_item_plots(data, base_output_file="accuracy_vs_len_item.png", model_name=None, test_name=None):
    """Create plots showing accuracy vs len_item, separated by n_tracked_updates"""
    if not data:
        print("No data to plot!")
        return []
        
    # Convert to DataFrame for easier handling
    df = pd.DataFrame(data)
    
    # Get unique n_tracked_updates values
    unique_updates = sorted(df['n_tracked_updates'].unique())
    
    result_dfs = []
    
    for n_updates in unique_updates:
        # Filter data for this n_tracked_updates value
        subset_df = df[df['n_tracked_updates'] == n_updates].copy()
        subset_df = subset_df.sort_values('len_item')
        
        # Create the plot
        plt.figure(figsize=(12, 8))
        
        # Plot with error bars
        plt.errorbar(
            subset_df['len_item'],
            subset_df['accuracy_mean'],
            yerr=subset_df['accuracy_ci95'],
            fmt='o-',
            capsize=5,
            markersize=8,
            label='Mean with 95% CI'
        )
        
        # Add some statistics
        max_acc = subset_df['accuracy_mean'].max()
        min_acc = subset_df['accuracy_mean'].min()
        mean_acc = subset_df['accuracy_mean'].mean()
        
        # Add text box with statistics
        stats_text = f'Max Accuracy: {max_acc:.3f}\nMin Accuracy: {min_acc:.3f}\nMean Accuracy: {mean_acc:.3f}\nData Points: {len(subset_df)}'
        plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8),
                 verticalalignment='top', fontsize=10)
        
        # **æ·»åŠ å¯¹æ•°åˆ»åº¦** - ä¸å…¶ä»–æ¨¡å¼ä¿æŒä¸€è‡´
        plt.xscale('log')
        
        # Set custom x-axis ticks to show each data point exactly
        plt.xticks(subset_df['len_item'], labels=subset_df['len_item'].astype(str), rotation=45, ha='right')
        plt.xlabel('Item Length (log scale)', fontsize=14)  # æ›´æ–°æ ‡ç­¾è¯´æ˜ä½¿ç”¨äº†å¯¹æ•°åˆ»åº¦
        plt.ylabel('Accuracy', fontsize=14)
        
        # Add title with detailed information
        title = f"Accuracy vs Item Length (n_tracked_updates={n_updates})"
        if model_name:
            title += f"\nModel: {model_name}"
        if test_name:
            title += f"\nTest: {test_name}"
        plt.title(title, fontsize=14)
        
        # Add grid
        plt.grid(True, alpha=0.3)
        
        # Generate output filename
        base_name = base_output_file.replace('.png', '')
        output_file = f"{base_name}_n_updates_{n_updates}.png"
        
        # Save the plot
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"\nğŸ“Š Plot saved as: {output_file}")
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯åˆ°DataFrame
        subset_df['model_name'] = model_name if model_name else 'Unknown'
        subset_df['ci95_method'] = 'Bootstrap (n=5000)'
        
        result_dfs.append(subset_df)
    
    return result_dfs

def extract_n_tracked_keys_from_dir(dir_name):
    """Extract n_tracked_keys value from directory name"""
    if "_ntrk-" in dir_name:
        try:
            return int(dir_name.split("_ntrk-")[1].split("_")[0])
        except:
            return None
    return None

def collect_data_nkeys_mode(base_dir):
    """Collect n_tracked_keys and accuracy data for test_nkeys tests"""
    data = []
    raw_data_list = []
    
    # Try to determine test name from path for config lookup
    test_name = None
    path_parts = base_dir.replace('\\', '/').split('/')
    for part in path_parts:
        if part.startswith('test_'):
            test_name = part
            break
    
    # Find all test directories with ntrk pattern
    pattern = os.path.join(base_dir, "*ntrk-*")
    test_dirs = sorted(glob.glob(pattern))
    
    print(f"Found {len(test_dirs)} test directories for n_tracked_keys analysis")
    
    for test_dir in test_dirs:
        dir_name = os.path.basename(test_dir)
        n_tracked_keys = extract_n_tracked_keys_from_dir(dir_name)
        n_updates = extract_n_tracked_updates(dir_name)
        
        if n_tracked_keys is None or n_updates is None:
            continue
            
        # Find the CSV file
        csv_pattern = os.path.join(test_dir, "*_trial.csv")
        csv_files = glob.glob(csv_pattern)
        
        if not csv_files:
            print(f"Warning: No CSV file found in {dir_name}")
            continue
            
        csv_file = csv_files[0]
        accuracy = extract_accuracy_from_csv(csv_file)
        
        if accuracy is not None:
            data.append({
                'n_tracked_keys': n_tracked_keys,
                'n_tracked_updates': n_updates,
                'accuracy_mean': accuracy['mean'],
                'accuracy_ci95': accuracy['ci95'],
                'n': accuracy['n'],
                'directory': dir_name
            })
            
            # æ·»åŠ åŸå§‹æ•°æ®åˆ°åˆ—è¡¨
            if 'raw_data' in accuracy:
                raw_df = accuracy['raw_data']
                raw_df['n_tracked_keys'] = n_tracked_keys
                raw_df['n_tracked_updates'] = n_updates
                raw_df['directory'] = dir_name
                raw_data_list.append(raw_df)
            
            print(f"âœ… n_tracked_keys={n_tracked_keys:2d}, n_updates={n_updates:2d}, accuracy={accuracy['mean']:.3f} Â± {accuracy['ci95']:.3f}")
        else:
            print(f"âŒ Failed to extract accuracy from {dir_name}")
    
    # ä¿å­˜åŸå§‹æ•°æ®åˆ°CSVæ–‡ä»¶
    if raw_data_list:
        raw_data_df = pd.concat(raw_data_list, ignore_index=True)
        current_dir = os.getcwd()
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        model_name = os.path.basename(base_dir)
        raw_data_file = os.path.join(current_dir, f'raw_accuracy_data_{test_name}_{model_name}_{timestamp}.csv')
        raw_data_df.to_csv(raw_data_file, index=False)
        print(f"\nğŸ“„ Raw data saved as: {raw_data_file}")
    
    return data

def create_nkeys_plots(data, base_output_file="accuracy_vs_nkeys.png", model_name=None, test_name=None):
    """Create plots showing accuracy vs n_tracked_keys, separated by n_tracked_updates"""
    if not data:
        print("No data to plot!")
        return []
        
    # Convert to DataFrame for easier handling
    df = pd.DataFrame(data)
    
    # Get unique n_tracked_updates values
    unique_updates = sorted(df['n_tracked_updates'].unique())
    
    result_dfs = []
    
    for n_updates in unique_updates:
        # Filter data for this n_tracked_updates value
        subset_df = df[df['n_tracked_updates'] == n_updates].copy()
        subset_df = subset_df.sort_values('n_tracked_keys')
        
        # Create the plot
        plt.figure(figsize=(12, 8))
        
        # Plot with error bars
        plt.errorbar(
            subset_df['n_tracked_keys'],
            subset_df['accuracy_mean'],
            yerr=subset_df['accuracy_ci95'],
            fmt='o-',
            capsize=5,
            markersize=8,
            label='Mean with 95% CI'
        )
        
        # Add some statistics
        max_acc = subset_df['accuracy_mean'].max()
        min_acc = subset_df['accuracy_mean'].min()
        mean_acc = subset_df['accuracy_mean'].mean()
        
        # Add text box with statistics
        stats_text = f'Max Accuracy: {max_acc:.3f}\nMin Accuracy: {min_acc:.3f}\nMean Accuracy: {mean_acc:.3f}\nData Points: {len(subset_df)}'
        plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8),
                 verticalalignment='top', fontsize=10)
        
        # Use log scale for better visualization (like default mode)
        plt.xscale('log')
        
        # Set custom x-axis ticks to show each data point exactly
        plt.xticks(subset_df['n_tracked_keys'], labels=subset_df['n_tracked_keys'].astype(str), rotation=45, ha='right')
        plt.xlabel('Number of Tracked Keys (log scale)', fontsize=14)
        plt.ylabel('Accuracy', fontsize=14)
        
        # Add title with detailed information
        title = f"Accuracy vs Number of Tracked Keys (n_tracked_updates={n_updates})"
        if model_name:
            title += f"\nModel: {model_name}"
        if test_name:
            title += f"\nTest: {test_name}"
        plt.title(title, fontsize=14)
        
        # Add grid
        plt.grid(True, alpha=0.3)
        
        # Generate output filename
        base_name = base_output_file.replace('.png', '')
        output_file = f"{base_name}_n_updates_{n_updates}.png"
        
        # Save the plot
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"\nğŸ“Š Plot saved as: {output_file}")
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯åˆ°DataFrame
        subset_df['model_name'] = model_name if model_name else 'Unknown'
        subset_df['ci95_method'] = 'Bootstrap (n=5000)'
        
        result_dfs.append(subset_df)
    
    return result_dfs

def main():
    parser = argparse.ArgumentParser(description="Plot accuracy vs n_tracked_updates, len_item, or n_tracked_keys")
    
    # Determine default path based on current working directory
    if os.path.basename(os.getcwd()) == "pi_automation":
        default_path = "../eval_pi/test_updates_custom_fast/gemini-2.0-flash"
    else:
        default_path = "eval_pi/test_updates_custom_fast/gemini-2.0-flash"
    
    parser.add_argument("--path", default=default_path,
                       help="Path to test results directory")
    parser.add_argument("--output", default="accuracy_plot.png",
                       help="Output plot filename")
    parser.add_argument("--csv", default="accuracy_summary.csv",
                       help="Output CSV filename")
    
    args = parser.parse_args()
    base_dir = args.path
    
    print("ğŸ” Analyzing Test Results")
    print("=" * 60)
    print(f"ğŸ“ Source: {base_dir}")
    
    if not os.path.exists(base_dir):
        print(f"âŒ Directory not found: {base_dir}")
        return
    
    # Extract model and test parameters
    model_name = extract_model_from_path(base_dir)
    test_name, random_update = extract_test_params_from_path(base_dir)
    
    # **æ£€æµ‹æµ‹è¯•ç±»å‹** - æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥
    is_len_item_test = test_name and test_name.startswith('test_itemlen')
    is_nkeys_test = test_name and test_name.startswith('test_nkeys')
    
    if is_len_item_test:
        print("ğŸ”¬ Detected len_item test - using len_item analysis mode")
        
        # ä½¿ç”¨ len_item æ¨¡å¼
        data = collect_data_len_item_mode(base_dir)
        
        if not data:
            print("âŒ No data collected!")
            return
        
        print(f"\nğŸ“Š Collected {len(data)} data points")
        
        # åˆ›å»º len_item å›¾è¡¨
        result_dfs = create_len_item_plots(data, args.output, model_name, test_name)
        
        # ä¿å­˜CSVæ–‡ä»¶ï¼ˆæ¯ä¸ª n_tracked_updates ä¸€ä¸ªæ–‡ä»¶ï¼‰
        for df in result_dfs:
            n_updates = df['n_tracked_updates'].iloc[0]
            csv_file = args.csv.replace('.csv', f'_n_updates_{n_updates}.csv')
            df.to_csv(csv_file, index=False)
            print(f"ğŸ“„ Data saved as: {csv_file}")
            
            # æ‰“å°æ‘˜è¦è¡¨
            print(f"\nğŸ“‹ Summary Table (n_tracked_updates={n_updates}):")
            print("-" * 30)
            print("len_item | accuracy")
            print("-" * 30)
            for _, row in df.iterrows():
                print(f"{row['len_item']:8d} | {row['accuracy_mean']:.3f} Â± {row['accuracy_ci95']:.3f}")
            print("-" * 30)
    
    elif is_nkeys_test:
        print("ğŸ”‘ Detected n_tracked_keys test - using n_tracked_keys analysis mode")
        
        # ä½¿ç”¨ nkeys æ¨¡å¼
        data = collect_data_nkeys_mode(base_dir)
        
        if not data:
            print("âŒ No data collected!")
            return
        
        print(f"\nğŸ“Š Collected {len(data)} data points")
        
        # åˆ›å»º nkeys å›¾è¡¨
        result_dfs = create_nkeys_plots(data, args.output, model_name, test_name)
        
        # ä¿å­˜CSVæ–‡ä»¶ï¼ˆæ¯ä¸ª n_tracked_updates ä¸€ä¸ªæ–‡ä»¶ï¼‰
        for df in result_dfs:
            n_updates = df['n_tracked_updates'].iloc[0]
            csv_file = args.csv.replace('.csv', f'_n_updates_{n_updates}.csv')
            df.to_csv(csv_file, index=False)
            print(f"ğŸ“„ Data saved as: {csv_file}")
            
            # æ‰“å°æ‘˜è¦è¡¨
            print(f"\nğŸ“‹ Summary Table (n_tracked_updates={n_updates}):")
            print("-" * 35)
            print("n_tracked_keys | accuracy")
            print("-" * 35)
            for _, row in df.iterrows():
                print(f"{row['n_tracked_keys']:13d} | {row['accuracy_mean']:.3f} Â± {row['accuracy_ci95']:.3f}")
            print("-" * 35)
    
    else:
        # **å®Œå…¨ä½¿ç”¨åŸæœ‰çš„é»˜è®¤è¡Œä¸º** - æ²¡æœ‰ä»»ä½•æ›´æ”¹
        print("ğŸ“ˆ Using default n_tracked_updates analysis mode")
        
        # ä½¿ç”¨åŸæœ‰çš„æ•°æ®æ”¶é›†å’Œç»˜å›¾å‡½æ•°
        data = collect_data(base_dir)
        
        if not data:
            print("âŒ No data collected!")
            return
        
        print(f"\nğŸ“Š Collected {len(data)} data points")
        
        # ä½¿ç”¨åŸæœ‰çš„ç»˜å›¾å‡½æ•°
        df = create_plot(data, args.output, model_name, test_name, random_update)
        
        # æ‰“å°åŸæœ‰çš„æ‘˜è¦è¡¨
        print("\nğŸ“‹ Summary Table:")
        print("-" * 40)
        print("n_tracked_updates | accuracy")
        print("-" * 40)
        for _, row in df.iterrows():
            print(f"{row['n_tracked_updates']:16d} | {row['accuracy_mean']:.3f} Â± {row['accuracy_ci95']:.3f}")
        print("-" * 40)
        
        # ä¿å­˜åŸæœ‰æ ¼å¼çš„CSV
        df.to_csv(args.csv, index=False)
        print(f"ğŸ“„ Data saved as: {args.csv}")
        print(f"   - Model: {model_name}")
        print(f"   - CI95 Method: Bootstrap (n=5000)")

if __name__ == "__main__":
    main() 